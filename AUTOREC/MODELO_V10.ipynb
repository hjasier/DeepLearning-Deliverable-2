{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  Timestamp\n",
       "0       1     1193       5  978300760\n",
       "1       1      661       3  978302109\n",
       "2       1      914       3  978301968\n",
       "3       1     3408       4  978300275\n",
       "4       1     2355       5  978824291"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "movies_path = \"ml-1m/movies.dat\"\n",
    "ratings_path = \"ml-1m/ratings.dat\"\n",
    "users_path = \"ml-1m/users.dat\"\n",
    "\n",
    "\n",
    "# Carga de los datos\n",
    "users = pd.read_csv(users_path, sep=\"::\", engine=\"python\", names=[\"UserID\", \"Gender\", \"Age\", \"Occupation\", \"Zip-code\"], encoding=\"latin-1\")\n",
    "movies = pd.read_csv(movies_path, sep=\"::\", engine=\"python\", names=[\"MovieID\", \"Title\", \"Genres\"], encoding=\"latin-1\")\n",
    "ratings = pd.read_csv(ratings_path, sep=\"::\", engine=\"python\", names=[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"], encoding=\"latin-1\")\n",
    "\n",
    "# Mostrar primeras filas\n",
    "ratings.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "user_enc = LabelEncoder()\n",
    "movie_enc = LabelEncoder()\n",
    "\n",
    "ratings['user'] = user_enc.fit_transform(ratings['UserID'])\n",
    "ratings['movie'] = movie_enc.fit_transform(ratings['MovieID'])\n",
    "\n",
    "num_users = ratings['user'].nunique()\n",
    "num_movies = ratings['movie'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "max_seq_len = 10  # longitud fija de historial\n",
    "\n",
    "user_histories = defaultdict(list)\n",
    "sequence_data = []\n",
    "\n",
    "# Ordenamos por timestamp\n",
    "ratings = ratings.sort_values(by=['user', 'Timestamp'])\n",
    "\n",
    "# Generar secuencias\n",
    "for row in ratings.itertuples():\n",
    "    u, m = row.user, row.movie\n",
    "    hist = user_histories[u][-max_seq_len:]\n",
    "    if len(hist) >= 1:  # solo si hay al menos un ítem en historial\n",
    "        padded_hist = [0] * (max_seq_len - len(hist)) + hist  # pad left\n",
    "        sequence_data.append((padded_hist, m))\n",
    "    user_histories[u].append(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class GRU4RecDataset(Dataset):\n",
    "    def __init__(self, sequence_data):\n",
    "        self.sequences = [torch.tensor(s, dtype=torch.long) for s, _ in sequence_data]\n",
    "        self.targets = [torch.tensor(t, dtype=torch.long) for _, t in sequence_data]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.targets[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "full_dataset = GRU4RecDataset(sequence_data)\n",
    "\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class GRU4RecModel(nn.Module):\n",
    "    def __init__(self, num_items, embedding_dim=64, hidden_dim=128, num_layers=1, dropout=0.2):\n",
    "        super(GRU4RecModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_items, embedding_dim, padding_idx=0)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "        self.output_layer = nn.Linear(hidden_dim, num_items)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        emb = self.embedding(input_seq)                         # (batch, seq_len, emb_dim)\n",
    "        gru_out, _ = self.gru(emb)                              # (batch, seq_len, hidden_dim)\n",
    "        last_hidden = gru_out[:, -1, :]                         # última salida (batch, hidden_dim)\n",
    "        logits = self.output_layer(last_hidden)                # (batch, num_items)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gru4rec_model(model, train_loader, val_loader, epochs=10, lr=0.001, device='cpu'):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for input_seq, target in train_loader:\n",
    "            input_seq, target = input_seq.to(device), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(input_seq)\n",
    "            loss = criterion(logits, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        # Validación\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for input_seq, target in val_loader:\n",
    "                input_seq, target = input_seq.to(device), target.to(device)\n",
    "                logits = model(input_seq)\n",
    "                loss = criterion(logits, target)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                correct += (preds == target).sum().item()\n",
    "                total += target.size(0)\n",
    "\n",
    "        acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {total_train_loss/len(train_loader):.4f}, \"\n",
    "              f\"Val Loss = {val_loss/len(val_loader):.4f}, Val Acc = {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjasi/Documentos/DeepLearning/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 6.4826, Val Loss = 5.9732, Val Acc = 0.0384\n",
      "Epoch 2: Train Loss = 5.7956, Val Loss = 5.7845, Val Acc = 0.0469\n",
      "Epoch 3: Train Loss = 5.6105, Val Loss = 5.7196, Val Acc = 0.0494\n",
      "Epoch 4: Train Loss = 5.5017, Val Loss = 5.6959, Val Acc = 0.0517\n",
      "Epoch 5: Train Loss = 5.4248, Val Loss = 5.6919, Val Acc = 0.0517\n",
      "Epoch 6: Train Loss = 5.3652, Val Loss = 5.6956, Val Acc = 0.0524\n",
      "Epoch 7: Train Loss = 5.3162, Val Loss = 5.7047, Val Acc = 0.0528\n",
      "Epoch 8: Train Loss = 5.2747, Val Loss = 5.7191, Val Acc = 0.0521\n",
      "Epoch 9: Train Loss = 5.2388, Val Loss = 5.7325, Val Acc = 0.0527\n",
      "Epoch 10: Train Loss = 5.2076, Val Loss = 5.7504, Val Acc = 0.0523\n"
     ]
    }
   ],
   "source": [
    "gru_model = GRU4RecModel(num_items=num_movies, embedding_dim=64, hidden_dim=128).to(device)\n",
    "\n",
    "train_gru4rec_model(\n",
    "    model=gru_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=10,\n",
    "    lr=0.001,\n",
    "    device=device\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
