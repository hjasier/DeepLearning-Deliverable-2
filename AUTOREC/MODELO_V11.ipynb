{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  Timestamp\n",
       "0       1     1193       5  978300760\n",
       "1       1      661       3  978302109\n",
       "2       1      914       3  978301968\n",
       "3       1     3408       4  978300275\n",
       "4       1     2355       5  978824291"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "movies_path = \"ml-1m/movies.dat\"\n",
    "ratings_path = \"ml-1m/ratings.dat\"\n",
    "users_path = \"ml-1m/users.dat\"\n",
    "\n",
    "\n",
    "# Carga de los datos\n",
    "users = pd.read_csv(users_path, sep=\"::\", engine=\"python\", names=[\"UserID\", \"Gender\", \"Age\", \"Occupation\", \"Zip-code\"], encoding=\"latin-1\")\n",
    "movies = pd.read_csv(movies_path, sep=\"::\", engine=\"python\", names=[\"MovieID\", \"Title\", \"Genres\"], encoding=\"latin-1\")\n",
    "ratings = pd.read_csv(ratings_path, sep=\"::\", engine=\"python\", names=[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"], encoding=\"latin-1\")\n",
    "\n",
    "# Mostrar primeras filas\n",
    "ratings.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "user_enc = LabelEncoder()\n",
    "movie_enc = LabelEncoder()\n",
    "\n",
    "ratings['user'] = user_enc.fit_transform(ratings['UserID'])\n",
    "ratings['movie'] = movie_enc.fit_transform(ratings['MovieID'])\n",
    "\n",
    "num_users = ratings['user'].nunique()\n",
    "num_movies = ratings['movie'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "max_seq_len = 10  # longitud fija de historial\n",
    "\n",
    "user_histories = defaultdict(list)\n",
    "sequence_data = []\n",
    "\n",
    "# Ordenamos por timestamp\n",
    "ratings = ratings.sort_values(by=['user', 'Timestamp'])\n",
    "\n",
    "# Generar secuencias\n",
    "for row in ratings.itertuples():\n",
    "    u, m = row.user, row.movie\n",
    "    hist = user_histories[u][-max_seq_len:]\n",
    "    if len(hist) >= 1:  # solo si hay al menos un ítem en historial\n",
    "        padded_hist = [0] * (max_seq_len - len(hist)) + hist  # pad left\n",
    "        sequence_data.append((padded_hist, m))\n",
    "    user_histories[u].append(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class GRU4RecNegDataset(Dataset):\n",
    "    def __init__(self, sequence_data, num_items, num_negatives=20):\n",
    "        self.sequence_data = sequence_data\n",
    "        self.num_items = num_items\n",
    "        self.num_negatives = num_negatives\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequence_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq, pos_item = self.sequence_data[idx]\n",
    "        neg_items = []\n",
    "        while len(neg_items) < self.num_negatives:\n",
    "            neg = random.randint(1, self.num_items - 1)  # evitar 0 (padding)\n",
    "            if neg != pos_item:\n",
    "                neg_items.append(neg)\n",
    "\n",
    "        return (\n",
    "            torch.tensor(seq, dtype=torch.long),                    # input_seq\n",
    "            torch.tensor(pos_item, dtype=torch.long),              # positivo\n",
    "            torch.tensor(neg_items, dtype=torch.long)              # negativos\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "neg_dataset = GRU4RecNegDataset(sequence_data, num_items=num_movies, num_negatives=20)\n",
    "\n",
    "train_size = int(0.8 * len(neg_dataset))\n",
    "val_size = len(neg_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(neg_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU4RecRankingModel(nn.Module):\n",
    "    def __init__(self, num_items, embedding_dim=64, hidden_dim=128, num_layers=1, dropout=0.3):\n",
    "        super(GRU4RecRankingModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_items, embedding_dim, padding_idx=0)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "        self.item_proj = nn.Embedding(num_items, hidden_dim)  # para comparar con salida de GRU\n",
    "\n",
    "    def forward(self, input_seq, pos_items, neg_items):\n",
    "        # input_seq: (B, seq_len), pos_items: (B,), neg_items: (B, N)\n",
    "        emb = self.embedding(input_seq)                         # (B, seq_len, emb_dim)\n",
    "        gru_out, _ = self.gru(emb)                              # (B, seq_len, hidden_dim)\n",
    "        user_emb = gru_out[:, -1, :]                            # (B, hidden_dim)\n",
    "\n",
    "        # Positivo\n",
    "        pos_emb = self.item_proj(pos_items)                     # (B, hidden_dim)\n",
    "        pos_scores = torch.sum(user_emb * pos_emb, dim=1)       # (B,)\n",
    "\n",
    "        # Negativos\n",
    "        neg_emb = self.item_proj(neg_items)                     # (B, N, hidden_dim)\n",
    "        user_emb_exp = user_emb.unsqueeze(1).expand_as(neg_emb)  # (B, N, hidden_dim)\n",
    "        neg_scores = torch.sum(user_emb_exp * neg_emb, dim=2)   # (B, N)\n",
    "\n",
    "        return pos_scores, neg_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gru4rec_ranking(model, train_loader, val_loader, epochs=10, lr=0.001, device='cpu'):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for input_seq, pos_item, neg_items in train_loader:\n",
    "            input_seq = input_seq.to(device)\n",
    "            pos_item = pos_item.to(device)\n",
    "            neg_items = neg_items.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pos_scores, neg_scores = model(input_seq, pos_item, neg_items)\n",
    "\n",
    "            # Construir etiquetas: 1 para positivo, 0 para negativos\n",
    "            target_pos = torch.ones_like(pos_scores)\n",
    "            target_neg = torch.zeros_like(neg_scores)\n",
    "\n",
    "            # Calcular BCE\n",
    "            loss_pos = criterion(pos_scores, target_pos)\n",
    "            loss_neg = criterion(neg_scores, target_neg)\n",
    "            loss = loss_pos + loss_neg.mean()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {total_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjasi/Documentos/DeepLearning/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 1.0950\n",
      "Epoch 2: Train Loss = 0.8126\n",
      "Epoch 3: Train Loss = 0.7095\n",
      "Epoch 4: Train Loss = 0.6522\n",
      "Epoch 5: Train Loss = 0.6134\n",
      "Epoch 6: Train Loss = 0.5850\n",
      "Epoch 7: Train Loss = 0.5632\n",
      "Epoch 8: Train Loss = 0.5448\n",
      "Epoch 9: Train Loss = 0.5289\n",
      "Epoch 10: Train Loss = 0.5150\n",
      "Epoch 11: Train Loss = 0.5018\n",
      "Epoch 12: Train Loss = 0.4904\n",
      "Epoch 13: Train Loss = 0.4794\n",
      "Epoch 14: Train Loss = 0.4694\n",
      "Epoch 15: Train Loss = 0.4596\n",
      "Epoch 16: Train Loss = 0.4505\n",
      "Epoch 17: Train Loss = 0.4417\n",
      "Epoch 18: Train Loss = 0.4336\n",
      "Epoch 19: Train Loss = 0.4260\n",
      "Epoch 20: Train Loss = 0.4184\n",
      "Epoch 21: Train Loss = 0.4113\n",
      "Epoch 22: Train Loss = 0.4046\n",
      "Epoch 23: Train Loss = 0.3979\n",
      "Epoch 24: Train Loss = 0.3922\n",
      "Epoch 25: Train Loss = 0.3858\n",
      "Epoch 26: Train Loss = 0.3804\n",
      "Epoch 27: Train Loss = 0.3745\n",
      "Epoch 28: Train Loss = 0.3695\n",
      "Epoch 29: Train Loss = 0.3648\n",
      "Epoch 30: Train Loss = 0.3601\n"
     ]
    }
   ],
   "source": [
    "ranking_model = GRU4RecRankingModel(num_items=num_movies, embedding_dim=64, hidden_dim=128).to(device)\n",
    "\n",
    "train_gru4rec_ranking(\n",
    "    model=ranking_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,  # aún no la usamos, pero podemos extender para Recall@10 luego\n",
    "    epochs=30,\n",
    "    lr=0.001,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_gru4rec_recall_at_k(model, val_loader, k=10, device='cpu'):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    hits = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_seq, pos_item, _ in val_loader:\n",
    "            input_seq = input_seq.to(device)\n",
    "            pos_item = pos_item.to(device)\n",
    "\n",
    "            # Puntuaciones para todos los ítems\n",
    "            emb = model.embedding(input_seq)                # (B, L, emb_dim)\n",
    "            gru_out, _ = model.gru(emb)                     # (B, L, hidden_dim)\n",
    "            user_emb = gru_out[:, -1, :]                    # (B, hidden_dim)\n",
    "\n",
    "            all_items = torch.arange(model.item_proj.num_embeddings).to(device)\n",
    "            item_emb = model.item_proj(all_items)           # (num_items, hidden_dim)\n",
    "\n",
    "            scores = torch.matmul(user_emb, item_emb.T)     # (B, num_items)\n",
    "            top_k = torch.topk(scores, k=k, dim=1).indices  # (B, K)\n",
    "\n",
    "            for i in range(pos_item.size(0)):\n",
    "                if pos_item[i] in top_k[i]:\n",
    "                    hits += 1\n",
    "                total += 1\n",
    "\n",
    "    recall_at_k = hits / total\n",
    "    print(f\"Recall@{k}: {recall_at_k:.4f}\")\n",
    "    return recall_at_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.1473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.14730378104348352"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_gru4rec_recall_at_k(model=ranking_model, val_loader=val_loader, k=10, device=device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
