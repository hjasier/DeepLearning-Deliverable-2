{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the movieLens dataset\n",
    "\n",
    "u.data consists on 4 columns : user_id , movie_id , rating and timestamp\n",
    "\n",
    "u.genre    -- A list of the genres.\n",
    "\n",
    "u.user     -- Demographic information about the users; this is a tab\n",
    "              separated list of\n",
    "              user id | age | gender | occupation | zip code\n",
    "              The user ids are the ones used in the u.data data set.\n",
    "\n",
    "u.occupation -- A list of the occupations.\n",
    "\n",
    "\n",
    "u.info     -- The number of users, items, and ratings in the u data set.\n",
    "\n",
    "u.item     -- Information about the items (movies); this is a tab separated\n",
    "              list of\n",
    "              movie id | movie title | release date | video release date |\n",
    "              IMDb URL | unknown | Action | Adventure | Animation |\n",
    "              Children's | Comedy | Crime | Documentary | Drama | Fantasy |\n",
    "              Film-Noir | Horror | Musical | Mystery | Romance | Sci-Fi |\n",
    "              Thriller | War | Western |\n",
    "              The last 19 fields are the genres, a 1 indicates the movie\n",
    "              is of that genre, a 0 indicates it is not; movies can be in\n",
    "              several genres at once.\n",
    "              The movie ids are the ones used in the u.data data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings:\n",
      "   user_id  movie_id  rating  timestamp\n",
      "0      196       242       3  881250949\n",
      "1      186       302       3  891717742\n",
      "2       22       377       1  878887116\n",
      "3      244        51       2  880606923\n",
      "4      166       346       1  886397596\n",
      "\n",
      "Movies:\n",
      "   movie_id              title release_date  video_release_date  \\\n",
      "0         1   Toy Story (1995)  01-Jan-1995                 NaN   \n",
      "1         2   GoldenEye (1995)  01-Jan-1995                 NaN   \n",
      "2         3  Four Rooms (1995)  01-Jan-1995                 NaN   \n",
      "3         4  Get Shorty (1995)  01-Jan-1995                 NaN   \n",
      "4         5     Copycat (1995)  01-Jan-1995                 NaN   \n",
      "\n",
      "                                            IMDb_URL  genre_0  genre_1  \\\n",
      "0  http://us.imdb.com/M/title-exact?Toy%20Story%2...        0        0   \n",
      "1  http://us.imdb.com/M/title-exact?GoldenEye%20(...        0        1   \n",
      "2  http://us.imdb.com/M/title-exact?Four%20Rooms%...        0        0   \n",
      "3  http://us.imdb.com/M/title-exact?Get%20Shorty%...        0        1   \n",
      "4  http://us.imdb.com/M/title-exact?Copycat%20(1995)        0        0   \n",
      "\n",
      "   genre_2  genre_3  genre_4  ...  genre_9  genre_10  genre_11  genre_12  \\\n",
      "0        0        1        1  ...        0         0         0         0   \n",
      "1        1        0        0  ...        0         0         0         0   \n",
      "2        0        0        0  ...        0         0         0         0   \n",
      "3        0        0        0  ...        0         0         0         0   \n",
      "4        0        0        0  ...        0         0         0         0   \n",
      "\n",
      "   genre_13  genre_14  genre_15  genre_16  genre_17  genre_18  \n",
      "0         0         0         0         0         0         0  \n",
      "1         0         0         0         1         0         0  \n",
      "2         0         0         0         1         0         0  \n",
      "3         0         0         0         0         0         0  \n",
      "4         0         0         0         1         0         0  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "\n",
      "Users:\n",
      "   user_id  age gender  occupation zip_code\n",
      "0        1   24      M  technician    85711\n",
      "1        2   53      F       other    94043\n",
      "2        3   23      M      writer    32067\n",
      "3        4   24      M  technician    43537\n",
      "4        5   33      F       other    15213\n"
     ]
    }
   ],
   "source": [
    "data_path = \"ml-100k/u.data\"\n",
    "item_path = \"ml-100k/u.item\"\n",
    "user_path = \"ml-100k/u.user\"\n",
    "\n",
    "# Load u.data\n",
    "columns = [\"user_id\", \"movie_id\", \"rating\", \"timestamp\"]\n",
    "ratings = pd.read_csv(data_path, sep=\"\\t\", names=columns, encoding=\"latin-1\")\n",
    "\n",
    "# Load u.item\n",
    "item_columns = [\"movie_id\", \"title\", \"release_date\", \"video_release_date\", \"IMDb_URL\"] + [f\"genre_{i}\" for i in range(19)]\n",
    "movies = pd.read_csv(item_path, sep=\"|\", names=item_columns, encoding=\"latin-1\", usecols=range(24))\n",
    "\n",
    "# Load u.user\n",
    "user_columns = [\"user_id\", \"age\", \"gender\", \"occupation\", \"zip_code\"]\n",
    "users = pd.read_csv(user_path, sep=\"|\", names=user_columns, encoding=\"latin-1\")\n",
    "\n",
    "\n",
    "print(\"Ratings:\")\n",
    "print(ratings.head())\n",
    "print(\"\\nMovies:\")\n",
    "print(movies.head())\n",
    "print(\"\\nUsers:\")\n",
    "print(users.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de usuarios: 943\n",
      "Número de películas: 1682\n",
      "Número de ratings: 100000\n",
      "\n",
      "Distribución de ratings:\n",
      "rating\n",
      "4    34174\n",
      "3    27145\n",
      "5    21201\n",
      "2    11370\n",
      "1     6110\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribución de edades de usuarios:\n",
      "count    943.000000\n",
      "mean      34.051962\n",
      "std       12.192740\n",
      "min        7.000000\n",
      "25%       25.000000\n",
      "50%       31.000000\n",
      "75%       43.000000\n",
      "max       73.000000\n",
      "Name: age, dtype: float64\n",
      "\n",
      "Películas con más ratings:\n",
      "movie_id\n",
      "50     583\n",
      "258    509\n",
      "100    508\n",
      "181    507\n",
      "294    485\n",
      "286    481\n",
      "288    478\n",
      "1      452\n",
      "300    431\n",
      "121    429\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Número de usuarios: {ratings['user_id'].nunique()}\")\n",
    "print(f\"Número de películas: {ratings['movie_id'].nunique()}\")\n",
    "print(f\"Número de ratings: {ratings.shape[0]}\")\n",
    "\n",
    "print(\"\\nDistribución de ratings:\")\n",
    "\n",
    "print(ratings['rating'].value_counts())\n",
    "\n",
    "print(\"\\nDistribución de edades de usuarios:\")\n",
    "print(users['age'].describe())\n",
    "\n",
    "print(\"\\nPelículas con más ratings:\")\n",
    "print(ratings['movie_id'].value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations\n",
    "\n",
    "### Ratings (u.data)\n",
    "\n",
    "- There are 943 users and 1,682 movies with 100,000 ratings.\n",
    "- Most ratings are 4 and 3, indicating a tendency to rate higher rather than lower.\n",
    "- There are fewer ratings of 1 and 2, which could mean that users prefer not to rate bad movies rather than giving low scores.\n",
    "\n",
    "### Users (u.user)\n",
    "\n",
    "- Average age: 34 years.\n",
    "- Minimum age: 7 years, maximum age: 73 years.\n",
    "- Most users are between 25 and 43 years old (25%-75% percentiles).\n",
    "\n",
    "### Movies (u.item)\n",
    "\n",
    "- The most-rated movie has 583 ratings, while many others have very few ratings.\n",
    "- This indicates an issue with imbalanced data: some movies are very popular, while others receive almost no ratings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load genre Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          genre  genre_id\n",
      "0       unknown         0\n",
      "1        Action         1\n",
      "2     Adventure         2\n",
      "3     Animation         3\n",
      "4    Children's         4\n",
      "5        Comedy         5\n",
      "6         Crime         6\n",
      "7   Documentary         7\n",
      "8         Drama         8\n",
      "9       Fantasy         9\n",
      "10    Film-Noir        10\n",
      "11       Horror        11\n",
      "12      Musical        12\n",
      "13      Mystery        13\n",
      "14      Romance        14\n",
      "15       Sci-Fi        15\n",
      "16     Thriller        16\n",
      "17          War        17\n",
      "18      Western        18\n"
     ]
    }
   ],
   "source": [
    "genre_labels =  pd.read_csv(\"ml-100k/u.genre\", sep=\"|\", names=[\"genre\",\"genre_id\"], encoding=\"latin-1\")\n",
    "print(genre_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧹 Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ratings:\n",
      "   user_id  movie_id  rating\n",
      "0      196       242       3\n",
      "1      186       302       3\n",
      "2       22       377       1\n",
      "3      244        51       2\n",
      "4      166       346       1\n",
      "\n",
      "Users:\n",
      "   user_id  age  gender  occupation zip_code\n",
      "0        1   24       1  technician    85711\n",
      "1        2   53       0       other    94043\n",
      "2        3   23       1      writer    32067\n",
      "3        4   24       1  technician    43537\n",
      "4        5   33       0       other    15213\n",
      "\n",
      "Movies:\n",
      "   movie_id              title release_date  video_release_date  \\\n",
      "0         1   Toy Story (1995)  01-Jan-1995                 NaN   \n",
      "1         2   GoldenEye (1995)  01-Jan-1995                 NaN   \n",
      "2         3  Four Rooms (1995)  01-Jan-1995                 NaN   \n",
      "3         4  Get Shorty (1995)  01-Jan-1995                 NaN   \n",
      "4         5     Copycat (1995)  01-Jan-1995                 NaN   \n",
      "\n",
      "                                            IMDb_URL  \\\n",
      "0  http://us.imdb.com/M/title-exact?Toy%20Story%2...   \n",
      "1  http://us.imdb.com/M/title-exact?GoldenEye%20(...   \n",
      "2  http://us.imdb.com/M/title-exact?Four%20Rooms%...   \n",
      "3  http://us.imdb.com/M/title-exact?Get%20Shorty%...   \n",
      "4  http://us.imdb.com/M/title-exact?Copycat%20(1995)   \n",
      "\n",
      "                            genres  \n",
      "0  [Animation, Children's, Comedy]  \n",
      "1    [Action, Adventure, Thriller]  \n",
      "2                       [Thriller]  \n",
      "3          [Action, Comedy, Drama]  \n",
      "4         [Crime, Drama, Thriller]  \n"
     ]
    }
   ],
   "source": [
    "# Timestamp column is not useful\n",
    "ratings = ratings.drop(columns=[\"timestamp\"])\n",
    "\n",
    "# Convert gender to binary\n",
    "users[\"gender\"] = users[\"gender\"].map({\"M\": 1, \"F\": 0})\n",
    "\n",
    "\n",
    "genre_labels = genre_labels[\"genre\"].tolist()\n",
    "\n",
    "# Convertir géneros de 0s y 1s a listas de nombres\n",
    "movies[\"genres\"] = movies.apply(lambda row: [genre_labels[i] for i in range(19) if row[f\"genre_{i}\"] == 1], axis=1)\n",
    "\n",
    "# Eliminar columnas de género codificado\n",
    "movies = movies.drop(columns=[f\"genre_{i}\" for i in range(19)])\n",
    "\n",
    "# Mostrar cambios\n",
    "print(\"\\nRatings:\")\n",
    "print(ratings.head())\n",
    "print(\"\\nUsers:\")\n",
    "print(users.head())\n",
    "print(\"\\nMovies:\")\n",
    "print(movies.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codificar los IDs (user_id, movie_id)\n",
    "\n",
    "PyTorch trabaja mejor con índices consecutivos en vez de números aleatorios. Vamos a:\n",
    "\n",
    "    Mapear user_id y movie_id a índices consecutivos.\n",
    "\n",
    "    Guardar el número total de usuarios y películas para la red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total usuarios: 943, Total películas: 1682\n",
      "   user_id  movie_id  rating\n",
      "0      195       241       3\n",
      "1      185       301       3\n",
      "2       21       376       1\n",
      "3      243        50       2\n",
      "4      165       345       1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Crear mappings de ID a índice\n",
    "user2idx = {user_id: idx for idx, user_id in enumerate(users[\"user_id\"].unique())}\n",
    "movie2idx = {movie_id: idx for idx, movie_id in enumerate(movies[\"movie_id\"].unique())}\n",
    "\n",
    "# Aplicar mapeo\n",
    "ratings[\"user_id\"] = ratings[\"user_id\"].map(user2idx)\n",
    "ratings[\"movie_id\"] = ratings[\"movie_id\"].map(movie2idx)\n",
    "\n",
    "# Guardar número total de usuarios y películas\n",
    "num_users = len(user2idx)\n",
    "num_movies = len(movie2idx)\n",
    "\n",
    "print(f\"Total usuarios: {num_users}, Total películas: {num_movies}\")\n",
    "print(ratings.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividir en Train / Validation / Test\n",
    "\n",
    "    Train (70%) → Para entrenar el modelo.\n",
    "\n",
    "    Validation (15%) → Para ajustar hiperparámetros.\n",
    "\n",
    "    Test (15%) → Para evaluar el modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño Train: 70000, Validación: 15000, Test: 15000\n"
     ]
    }
   ],
   "source": [
    "# Dividir en train (70%), test (15%), validation (15%)\n",
    "train_data, temp_data = train_test_split(ratings, test_size=0.3, random_state=42)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Tamaño Train: {len(train_data)}, Validación: {len(val_data)}, Test: {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear PyTorch Dataset y DataLoader\n",
    "\n",
    "Para entrenar una red neuronal en PyTorch, necesitamos:\n",
    "\n",
    "✅ Crear un Dataset que convierta nuestros datos en tensores.\n",
    "\n",
    "✅ Usar DataLoader para cargar los datos en batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch de usuarios: tensor([ 23, 847, 601, 311, 810])\n",
      "Batch de películas: tensor([356, 133, 180,   0, 891])\n",
      "Batch de ratings: tensor([5., 5., 5., 5., 4.])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Define our dataset class \n",
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.users = torch.tensor(df[\"user_id\"].values, dtype=torch.long)\n",
    "        self.movies = torch.tensor(df[\"movie_id\"].values, dtype=torch.long)\n",
    "        self.ratings = torch.tensor(df[\"rating\"].values, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.movies[idx], self.ratings[idx]\n",
    "\n",
    "# Crear datasets\n",
    "train_dataset = MovieLensDataset(train_data)\n",
    "val_dataset = MovieLensDataset(val_data)\n",
    "test_dataset = MovieLensDataset(test_data)\n",
    "\n",
    "# Crear DataLoaders\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Verificar que funciona\n",
    "for users, movies, ratings in train_loader:\n",
    "    print(\"Batch de usuarios:\", users[:5])\n",
    "    print(\"Batch de películas:\", movies[:5])\n",
    "    print(\"Batch de ratings:\", ratings[:5])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🏗 Paso 4: Diseñar la Red Neuronal\n",
    "\n",
    "Vamos a usar una Embedding Neural Network, que es común en sistemas de recomendación. La estructura será:\n",
    "\n",
    "1️⃣ Capa de embeddings para representar usuarios y películas en un espacio de características.\n",
    "\n",
    "2️⃣ Capas completamente conectadas (Fully Connected, FC) para capturar interacciones no lineales.\n",
    "\n",
    "3️⃣ Salida con una única neurona que predice la calificación del usuario para la película.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "📚 Explicación de la arquitectura de RecommenderNet\n",
    "\n",
    "Este modelo está basado en una red neuronal de recomendaciones utilizando embeddings. Los embeddings son una forma eficiente de representar elementos (en este caso, usuarios y películas) en un espacio vectorial denso de menor dimensión, donde las relaciones semánticas entre estos elementos se pueden aprender.\n",
    "1️⃣ Embeddings\n",
    "\n",
    "    self.user_embedding y self.movie_embedding: Son capas de embeddings que transforman los identificadores de usuario y película en vectores de características de tamaño embedding_dim. Cada usuario y cada película se mapea a un vector de características en un espacio de dimensión embedding_dim (en este caso, 50).\n",
    "\n",
    "        El objetivo de los embeddings es que usuarios similares y películas similares tengan representaciones vectoriales cercanas en ese espacio.\n",
    "\n",
    "        La dimensión de los embeddings es un hiperparámetro importante: si es demasiado pequeño, el modelo puede no capturar toda la información; si es demasiado grande, el modelo puede volverse más complejo y propenso a sobreajustarse.\n",
    "\n",
    "2️⃣ Capas totalmente conectadas (Fully Connected Layers)\n",
    "\n",
    "    Después de obtener las representaciones de los usuarios y las películas a través de los embeddings, los concatenamos en un solo vector de tamaño 2 * embedding_dim (en este caso, 2 * 50 = 100).\n",
    "\n",
    "        fc1 toma esta concatenación y la mapea a un espacio de tamaño 128. Este es el primer capa densa. Elegí 128 porque es un buen valor intermedio que permite suficiente capacidad para aprender relaciones no lineales sin ser demasiado grande, lo que podría causar sobreajuste.\n",
    "\n",
    "        fc2 reduce la dimensión a 64. Esto hace que el modelo se haga más compacto y pueda aprender representaciones más generalizadas de las interacciones entre usuarios y películas. 64 es otra elección intermedia para evitar que el modelo sea demasiado grande, pero aún así tenga suficiente capacidad para aprender.\n",
    "\n",
    "        fc3 produce la salida final. Dado que estamos prediciendo una calificación, solo necesitamos una neurona en esta capa, que es la que nos da el rating estimado entre 1 y 5 (en este caso, valores continuos).\n",
    "\n",
    "3️⃣ Funciones de activación\n",
    "\n",
    "    ReLU: Se usa para introducir no linealidades entre las capas. Esta función activa los valores positivos y \"apaga\" los negativos (los pone en cero). De esta manera, el modelo puede aprender patrones complejos.\n",
    "\n",
    "4️⃣ Inicialización de pesos\n",
    "\n",
    "    _init_weights: Aquí inicializamos los pesos de las redes neuronales de manera que favorezcan el aprendizaje, usando una combinación de inicialización normal y uniforme de He para las capas totalmente conectadas. Esto ayuda a prevenir problemas de saturación en las activaciones.\n",
    "\n",
    "🔧 Elección de los hiperparámetros\n",
    "1️⃣ embedding_dim = 50\n",
    "\n",
    "    ¿Por qué 50?\n",
    "\n",
    "        Elegí 50 como valor inicial para el tamaño de los embeddings, ya que es un tamaño razonable para representar información de usuarios y películas en un espacio compacto sin perder mucha capacidad de aprendizaje.\n",
    "\n",
    "        Si fuera mucho mayor, los embeddings tendrían demasiados parámetros, lo que podría hacer que el modelo sea más complejo y propenso a sobreajustarse.\n",
    "\n",
    "        Si fuera mucho menor, podría no ser capaz de capturar adecuadamente la complejidad de las relaciones entre los usuarios y las películas.\n",
    "\n",
    "        50 es un valor equilibrado que suele ser suficiente para estos tipos de tareas de recomendación.\n",
    "\n",
    "2️⃣ Capas completamente conectadas:\n",
    "\n",
    "    fc1 = 128, fc2 = 64:\n",
    "\n",
    "        Estas capas permiten que el modelo capture interacciones más complejas entre los usuarios y las películas.\n",
    "\n",
    "        Elegí 128 y 64 porque son valores suficientemente grandes como para aprender relaciones no triviales entre los datos. Sin embargo, también son valores moderados, lo que ayuda a evitar que el modelo se haga demasiado complejo (lo cual podría generar sobreajuste) mientras sigue siendo lo suficientemente potente para capturar patrones.\n",
    "\n",
    "3️⃣ Capa de salida (fc3):\n",
    "\n",
    "    La capa de salida tiene un solo nodo porque estamos prediciendo un valor continuo (la calificación que un usuario le da a una película). El valor predicho estará entre 1 y 5, lo que corresponde a la calificación de la película."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RecommenderNet(nn.Module):\n",
    "    def __init__(self, num_users, num_movies, embedding_dim=100):\n",
    "        super(RecommenderNet, self).__init__()\n",
    "        \n",
    "        # Embeddings\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.movie_embedding = nn.Embedding(num_movies, embedding_dim)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(embedding_dim * 2, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)  # Salida: un número (rating)\n",
    "        \n",
    "        # Inicialización de pesos\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        nn.init.normal_(self.user_embedding.weight, std=0.01)\n",
    "        nn.init.normal_(self.movie_embedding.weight, std=0.01)\n",
    "        nn.init.kaiming_uniform_(self.fc1.weight)\n",
    "        nn.init.kaiming_uniform_(self.fc2.weight)\n",
    "        nn.init.kaiming_uniform_(self.fc3.weight)\n",
    "    \n",
    "    def forward(self, user_ids, movie_ids):\n",
    "        # Obtener embeddings\n",
    "        user_vec = self.user_embedding(user_ids)\n",
    "        movie_vec = self.movie_embedding(movie_ids)\n",
    "        \n",
    "        # Concatenar embeddings\n",
    "        x = torch.cat([user_vec, movie_vec], dim=1)\n",
    "        \n",
    "        # Pasar por capas densas\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x.squeeze()  # Salida final: un valor escalar (rating)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🏋️‍♂️ Paso 5: Entrenar el Modelo\n",
    "\n",
    "Ahora que hemos definido la arquitectura, necesitamos:\n",
    "\n",
    "    Definir la función de pérdida (Loss Function): Ya que estamos prediciendo calificaciones, la función de pérdida que vamos a usar es el Error Cuadrático Medio (MSE, por sus siglas en inglés).\n",
    "\n",
    "    Definir el optimizador: Vamos a usar el optimizador Adam, que es uno de los más populares para este tipo de tareas y funciona bien para redes neuronales de recomendación.\n",
    "\n",
    "    Entrenar el modelo: Ajustar los pesos del modelo usando el conjunto de entrenamiento, validación y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6 - Train Loss: 1.4613 - Validation Loss: 0.9103\n",
      "Mejor modelo guardado.\n",
      "Epoch 2/6 - Train Loss: 0.8791 - Validation Loss: 0.8959\n",
      "Mejor modelo guardado.\n",
      "Epoch 3/6 - Train Loss: 0.8415 - Validation Loss: 0.8815\n",
      "Mejor modelo guardado.\n",
      "Epoch 4/6 - Train Loss: 0.8117 - Validation Loss: 0.8760\n",
      "Mejor modelo guardado.\n",
      "Epoch 5/6 - Train Loss: 0.7733 - Validation Loss: 0.8710\n",
      "Mejor modelo guardado.\n",
      "Epoch 6/6 - Train Loss: 0.7301 - Validation Loss: 0.8677\n",
      "Mejor modelo guardado.\n",
      "Entrenamiento completado.\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Inicializamos el modelo\n",
    "model = RecommenderNet(num_users, num_movies, embedding_dim=100)\n",
    "\n",
    "# Definir la función de pérdida y el optimizador\n",
    "criterion = nn.MSELoss()  # Error cuadrático medio\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Función de entrenamiento con Early Stopping\n",
    "def train_model_early_stopping(model, train_loader, val_loader, criterion, optimizer, epochs=30, patience=5):\n",
    "    best_val_loss = float('inf')  # Mantener la mejor pérdida de validación\n",
    "    epochs_without_improvement = 0  # Contador de épocas sin mejora\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Poner el modelo en modo de entrenamiento\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for users, movies, ratings in train_loader:\n",
    "            optimizer.zero_grad()  # Limpiar los gradientes\n",
    "            \n",
    "            # Hacer las predicciones\n",
    "            predictions = model(users, movies)\n",
    "            \n",
    "            # Calcular la pérdida\n",
    "            loss = criterion(predictions, ratings)\n",
    "            \n",
    "            # Hacer backpropagation y actualizar los pesos\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Promediar la pérdida del entrenamiento\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        \n",
    "        # Validación\n",
    "        model.eval()  # Modo evaluación\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for users, movies, ratings in val_loader:\n",
    "                predictions = model(users, movies)\n",
    "                loss = criterion(predictions, ratings)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        # Imprimir resultados\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {avg_train_loss:.4f} - Validation Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "        # Guardar el modelo si la pérdida de validación mejora\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(\"Mejor modelo guardado.\")\n",
    "            epochs_without_improvement = 0  # Resetear el contador\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement >= patience:\n",
    "                print(\"No hubo mejora en la pérdida de validación, deteniendo el entrenamiento.\")\n",
    "                break\n",
    "    \n",
    "    print(\"Entrenamiento completado.\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Entrenar el modelo\n",
    "epochs = 6  \n",
    "trained_model = train_model_early_stopping(model, train_loader, val_loader, criterion, optimizer, epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.8745 - MSE: 0.8742\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()  # Establecer el modelo en modo evaluación\n",
    "    test_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for users, movies, ratings in test_loader:\n",
    "            # Hacer las predicciones\n",
    "            predictions = model(users, movies)\n",
    "            \n",
    "            # Calcular la pérdida\n",
    "            loss = criterion(predictions, ratings)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Almacenar las predicciones y las etiquetas reales para calcular métricas\n",
    "            all_preds.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(ratings.cpu().numpy())\n",
    "    \n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    mse = mean_squared_error(all_labels, all_preds)\n",
    "    print(f\"Test Loss: {avg_test_loss:.4f} - MSE: {mse:.4f}\")\n",
    "    \n",
    "    return mse\n",
    "\n",
    "# Evaluar el modelo\n",
    "test_mse = evaluate_model(trained_model, test_loader, criterion)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
