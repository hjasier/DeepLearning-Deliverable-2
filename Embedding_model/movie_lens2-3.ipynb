{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjasi/Documentos/DeepLearning/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the movieLens dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings:\n",
      "   UserID  MovieID  Rating  Timestamp\n",
      "0       1     1193       5  978300760\n",
      "1       1      661       3  978302109\n",
      "2       1      914       3  978301968\n",
      "3       1     3408       4  978300275\n",
      "4       1     2355       5  978824291\n",
      "\n",
      "Movies:\n",
      "   MovieID                               Title                        Genres\n",
      "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
      "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
      "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
      "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
      "4        5  Father of the Bride Part II (1995)                        Comedy\n",
      "\n",
      "Users:\n",
      "   UserID Gender  Age  Occupation Zip-code\n",
      "0       1      F    1          10    48067\n",
      "1       2      M   56          16    70072\n",
      "2       3      M   25          15    55117\n",
      "3       4      M   45           7    02460\n",
      "4       5      M   25          20    55455\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Rutas de los archivos\n",
    "movies_path = \"ml-1m/movies.dat\"\n",
    "ratings_path = \"ml-1m/ratings.dat\"\n",
    "users_path = \"ml-1m/users.dat\"\n",
    "\n",
    "# Carga de los datos\n",
    "# Cargar archivos\n",
    "users = pd.read_csv(\"ml-1m/users.dat\", sep=\"::\", engine=\"python\", \n",
    "                    names=[\"UserID\", \"Gender\", \"Age\", \"Occupation\", \"Zip-code\"], encoding=\"latin-1\")\n",
    "\n",
    "movies = pd.read_csv(\"ml-1m/movies.dat\", sep=\"::\", engine=\"python\", \n",
    "                     names=[\"MovieID\", \"Title\", \"Genres\"], encoding=\"latin-1\")\n",
    "\n",
    "ratings = pd.read_csv(\"ml-1m/ratings.dat\", sep=\"::\", engine=\"python\", \n",
    "                      names=[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"], encoding=\"latin-1\")\n",
    "\n",
    "# Mostrar primeras filas para verificar\n",
    "print(\"Ratings:\")\n",
    "print(ratings.head())\n",
    "print(\"\\nMovies:\")\n",
    "print(movies.head())\n",
    "print(\"\\nUsers:\")\n",
    "print(users.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total usuarios: 6040, Total películas: 3883\n"
     ]
    }
   ],
   "source": [
    "# Normalizar ratings de 1-5 a 0-1\n",
    "ratings[\"Rating\"] = (ratings[\"Rating\"] - 1.0) / 4.0\n",
    "\n",
    "# Convertir géneros a listas\n",
    "movies[\"Genres\"] = movies[\"Genres\"].apply(lambda x: x.split(\"|\"))\n",
    "\n",
    "# Codificar IDs\n",
    "user2idx = {user_id: idx for idx, user_id in enumerate(users[\"UserID\"].unique())}\n",
    "movie2idx = {movie_id: idx for idx, movie_id in enumerate(movies[\"MovieID\"].unique())}\n",
    "\n",
    "ratings[\"UserID\"] = ratings[\"UserID\"].map(user2idx)\n",
    "ratings[\"MovieID\"] = ratings[\"MovieID\"].map(movie2idx)\n",
    "\n",
    "num_users = len(user2idx)\n",
    "num_movies = len(movie2idx)\n",
    "\n",
    "print(f\"Total usuarios: {num_users}, Total películas: {num_movies}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividir en Train / Validation / Test\n",
    "\n",
    "    Train (70%) → Para entrenar el modelo.\n",
    "\n",
    "    Validation (15%) → Para ajustar hiperparámetros.\n",
    "\n",
    "    Test (15%) → Para evaluar el modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño Train: 700146, Validación: 150031, Test: 150032\n"
     ]
    }
   ],
   "source": [
    "# División: 70% Train, 15% Val, 15% Test\n",
    "train_data, temp_data = train_test_split(ratings, test_size=0.3, random_state=42)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Tamaño Train: {len(train_data)}, Validación: {len(val_data)}, Test: {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear PyTorch Dataset y DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.users = torch.tensor(df[\"UserID\"].values, dtype=torch.long)\n",
    "        self.movies = torch.tensor(df[\"MovieID\"].values, dtype=torch.long)\n",
    "        self.ratings = torch.tensor(df[\"Rating\"].values, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.movies[idx], self.ratings[idx]\n",
    "\n",
    "# Instanciar datasets\n",
    "train_dataset = MovieLensDataset(train_data)\n",
    "val_dataset = MovieLensDataset(val_data)\n",
    "test_dataset = MovieLensDataset(test_data)\n",
    "\n",
    "# Loaders\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalTunedRecommenderNet(nn.Module):\n",
    "    def __init__(self, num_users, num_movies):\n",
    "        super(FinalTunedRecommenderNet, self).__init__()\n",
    "        embedding_dim = 64  # De Optuna\n",
    "\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.movie_embedding = nn.Embedding(num_movies, embedding_dim)\n",
    "        nn.init.xavier_uniform_(self.user_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.movie_embedding.weight)\n",
    "\n",
    "        self.fc1 = nn.Linear(embedding_dim * 2, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.dropout1 = nn.Dropout(0.1467)\n",
    "\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.dropout2 = nn.Dropout(0.1018)\n",
    "\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, user_ids, movie_ids):\n",
    "        u = self.user_embedding(user_ids)\n",
    "        m = self.movie_embedding(movie_ids)\n",
    "        x = torch.cat([u, m], dim=1)\n",
    "        x = self.dropout1(F.leaky_relu(self.bn1(self.fc1(x))))\n",
    "        x = self.dropout2(F.leaky_relu(self.bn2(self.fc2(x))))\n",
    "        x = F.leaky_relu(self.fc3(x))\n",
    "        return self.output(x).squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar el Modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeeperRecommenderNet(nn.Module):\n",
    "    def __init__(self, num_users, num_movies, embedding_dim=128):\n",
    "        super(DeeperRecommenderNet, self).__init__()\n",
    "\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.movie_embedding = nn.Embedding(num_movies, embedding_dim)\n",
    "\n",
    "        # Inicialización Xavier\n",
    "        nn.init.xavier_uniform_(self.user_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.movie_embedding.weight)\n",
    "\n",
    "        self.fc1 = nn.Linear(embedding_dim * 2, 512)\n",
    "        self.dropout1 = nn.Dropout(0.4)\n",
    "\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "\n",
    "        self.output = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, user_ids, movie_ids):\n",
    "        user_vec = self.user_embedding(user_ids)\n",
    "        movie_vec = self.movie_embedding(movie_ids)\n",
    "\n",
    "        x = torch.cat([user_vec, movie_vec], dim=1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        x = self.output(x)\n",
    "        return x.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FinalTunedRecommenderNet(num_users, num_movies)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=0.000374,  # De Optuna\n",
    "    weight_decay=7.49e-6  # De Optuna\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=50, patience=5, clip_value=1.0):\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for users, movies, ratings in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(users, movies)\n",
    "            loss = criterion(predictions, ratings)\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip_value)\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # Validación\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for users, movies, ratings in val_loader:\n",
    "                predictions = model(users, movies)\n",
    "                loss = criterion(predictions, ratings)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # Guardar mejor modelo y optimizer\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict()\n",
    "            }, \"best_model.pth\")\n",
    "            print(\"🟢 Mejor modelo guardado.\")\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement >= patience:\n",
    "                print(\"🛑 Early stopping: no mejora en validación.\")\n",
    "                break\n",
    "\n",
    "    print(\"✅ Entrenamiento finalizado.\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 0.0571 | Val Loss: 0.0525\n",
      "🟢 Mejor modelo guardado.\n",
      "Epoch 2/50 | Train Loss: 0.0509 | Val Loss: 0.0512\n",
      "🟢 Mejor modelo guardado.\n",
      "Epoch 3/50 | Train Loss: 0.0488 | Val Loss: 0.0494\n",
      "🟢 Mejor modelo guardado.\n",
      "Epoch 4/50 | Train Loss: 0.0470 | Val Loss: 0.0488\n",
      "🟢 Mejor modelo guardado.\n",
      "Epoch 5/50 | Train Loss: 0.0452 | Val Loss: 0.0482\n",
      "🟢 Mejor modelo guardado.\n",
      "Epoch 6/50 | Train Loss: 0.0436 | Val Loss: 0.0481\n",
      "🟢 Mejor modelo guardado.\n",
      "Epoch 7/50 | Train Loss: 0.0422 | Val Loss: 0.0477\n",
      "🟢 Mejor modelo guardado.\n",
      "Epoch 8/50 | Train Loss: 0.0408 | Val Loss: 0.0478\n",
      "Epoch 9/50 | Train Loss: 0.0396 | Val Loss: 0.0480\n",
      "Epoch 10/50 | Train Loss: 0.0386 | Val Loss: 0.0485\n",
      "Epoch 11/50 | Train Loss: 0.0377 | Val Loss: 0.0486\n",
      "Epoch 12/50 | Train Loss: 0.0369 | Val Loss: 0.0491\n",
      "🛑 Early stopping: no mejora en validación.\n",
      "✅ Entrenamiento finalizado.\n"
     ]
    }
   ],
   "source": [
    "# Entrenar\n",
    "trained_model = train_model(model, train_loader, val_loader, criterion, optimizer, epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for FinalTunedRecommenderNet:\n\tMissing key(s) in state_dict: \"user_embedding.weight\", \"movie_embedding.weight\", \"fc1.weight\", \"fc1.bias\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"fc2.weight\", \"fc2.bias\", \"bn2.weight\", \"bn2.bias\", \"bn2.running_mean\", \"bn2.running_var\", \"fc3.weight\", \"fc3.bias\", \"output.weight\", \"output.bias\". \n\tUnexpected key(s) in state_dict: \"model_state_dict\", \"optimizer_state_dict\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Crear una nueva instancia y cargar pesos\u001b[39;00m\n\u001b[32m      2\u001b[39m best_model = FinalTunedRecommenderNet(num_users, num_movies)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mbest_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbest_model.pth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m best_model.eval()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/DeepLearning/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:2581\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2573\u001b[39m         error_msgs.insert(\n\u001b[32m   2574\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2575\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2576\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2577\u001b[39m             ),\n\u001b[32m   2578\u001b[39m         )\n\u001b[32m   2580\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2581\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2582\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2583\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2584\u001b[39m         )\n\u001b[32m   2585\u001b[39m     )\n\u001b[32m   2586\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for FinalTunedRecommenderNet:\n\tMissing key(s) in state_dict: \"user_embedding.weight\", \"movie_embedding.weight\", \"fc1.weight\", \"fc1.bias\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"fc2.weight\", \"fc2.bias\", \"bn2.weight\", \"bn2.bias\", \"bn2.running_mean\", \"bn2.running_var\", \"fc3.weight\", \"fc3.bias\", \"output.weight\", \"output.bias\". \n\tUnexpected key(s) in state_dict: \"model_state_dict\", \"optimizer_state_dict\". "
     ]
    }
   ],
   "source": [
    "# Crear una nueva instancia y cargar pesos\n",
    "best_model = FinalTunedRecommenderNet(num_users, num_movies)\n",
    "best_model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "best_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for users, movies, ratings in test_loader:\n",
    "            predictions = model(users, movies)\n",
    "            loss = criterion(predictions, ratings)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            all_preds.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(ratings.cpu().numpy())\n",
    "\n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "\n",
    "    # Convertir a numpy arrays\n",
    "    all_preds = np.clip(np.array(all_preds), 0.0, 1.0)  # clipping\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # Escala original [1–5]\n",
    "    preds_original = all_preds * 4 + 1\n",
    "    labels_original = all_labels * 4 + 1\n",
    "\n",
    "    mse = mean_squared_error(labels_original, preds_original)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(labels_original, preds_original)\n",
    "\n",
    "    print(f\"🔍 Test MSE (1-5): {mse:.4f}\")\n",
    "    print(f\"📉 Test RMSE (1-5): {rmse:.4f}\")\n",
    "    print(f\"📊 Test MAE  (1-5): {mae:.4f}\")\n",
    "    \n",
    "    return mse, rmse, mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Test MSE (1-5): 0.7844\n",
      "📉 Test RMSE (1-5): 0.8857\n",
      "📊 Test MAE  (1-5): 0.6908\n"
     ]
    }
   ],
   "source": [
    "mse, rmse, mae = evaluate_model(model, test_loader, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(trial, num_users, num_movies):\n",
    "    embedding_dim = trial.suggest_categorical(\"embedding_dim\", [32, 64, 128])\n",
    "\n",
    "    dropout1 = trial.suggest_float(\"dropout1\", 0.0, 0.5)\n",
    "    dropout2 = trial.suggest_float(\"dropout2\", 0.0, 0.5)\n",
    "\n",
    "    class TunedNet(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "            self.movie_embedding = nn.Embedding(num_movies, embedding_dim)\n",
    "            nn.init.xavier_uniform_(self.user_embedding.weight)\n",
    "            nn.init.xavier_uniform_(self.movie_embedding.weight)\n",
    "\n",
    "            self.fc1 = nn.Linear(embedding_dim * 2, 256)\n",
    "            self.bn1 = nn.BatchNorm1d(256)\n",
    "            self.dropout1 = nn.Dropout(dropout1)\n",
    "\n",
    "            self.fc2 = nn.Linear(256, 128)\n",
    "            self.bn2 = nn.BatchNorm1d(128)\n",
    "            self.dropout2 = nn.Dropout(dropout2)\n",
    "\n",
    "            self.fc3 = nn.Linear(128, 64)\n",
    "            self.output = nn.Linear(64, 1)\n",
    "\n",
    "        def forward(self, user_ids, movie_ids):\n",
    "            user_vec = self.user_embedding(user_ids)\n",
    "            movie_vec = self.movie_embedding(movie_ids)\n",
    "            x = torch.cat([user_vec, movie_vec], dim=1)\n",
    "            x = self.dropout1(F.leaky_relu(self.bn1(self.fc1(x))))\n",
    "            x = self.dropout2(F.leaky_relu(self.bn2(self.fc2(x))))\n",
    "            x = F.leaky_relu(self.fc3(x))\n",
    "            x = self.output(x)\n",
    "            return x.squeeze()\n",
    "\n",
    "    return TunedNet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    model = build_model(trial, num_users, num_movies)\n",
    "\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-4, 1e-2)\n",
    "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-6, 1e-2)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Entrenamiento simplificado (menos épocas para velocidad)\n",
    "    for epoch in range(5):  \n",
    "        model.train()\n",
    "        for users, movies, ratings in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(users, movies)\n",
    "            loss = criterion(predictions, ratings)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "    # Validación final\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for users, movies, ratings in val_loader:\n",
    "            predictions = model(users, movies)\n",
    "            loss = criterion(predictions, ratings)\n",
    "            val_loss += loss.item()\n",
    "    return val_loss / len(val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 14:19:40,455] A new study created in memory with name: no-name-b6e4b2b4-2a85-4496-bcc9-dad90370b5a2\n",
      "/tmp/ipykernel_64544/3222869113.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-4, 1e-2)\n",
      "/tmp/ipykernel_64544/3222869113.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-6, 1e-2)\n",
      "[I 2025-04-06 14:22:14,198] Trial 0 finished with value: 0.05928875238198758 and parameters: {'embedding_dim': 32, 'dropout1': 0.3538981485222143, 'dropout2': 0.46671717254394446, 'lr': 0.003943275259744605, 'weight_decay': 2.884341152524564e-05}. Best is trial 0 with value: 0.05928875238198758.\n",
      "[I 2025-04-06 14:25:11,145] Trial 1 finished with value: 0.04896031740262075 and parameters: {'embedding_dim': 64, 'dropout1': 0.17618018395729507, 'dropout2': 0.16578724067694084, 'lr': 0.000957316937795701, 'weight_decay': 3.1424899941556134e-06}. Best is trial 1 with value: 0.04896031740262075.\n",
      "[I 2025-04-06 14:28:07,008] Trial 2 finished with value: 0.05364347833628748 and parameters: {'embedding_dim': 64, 'dropout1': 0.35726815996261263, 'dropout2': 0.22585020292348046, 'lr': 0.0007335139912860892, 'weight_decay': 0.0007538993575730955}. Best is trial 1 with value: 0.04896031740262075.\n",
      "[I 2025-04-06 14:30:40,100] Trial 3 finished with value: 0.05663217957634145 and parameters: {'embedding_dim': 32, 'dropout1': 0.05114325462180158, 'dropout2': 0.22285537984816461, 'lr': 0.005416501375370738, 'weight_decay': 5.7728196280499734e-05}. Best is trial 1 with value: 0.04896031740262075.\n",
      "[I 2025-04-06 14:34:55,058] Trial 4 finished with value: 0.05009943692732955 and parameters: {'embedding_dim': 128, 'dropout1': 0.22895305784645636, 'dropout2': 0.49071352300453774, 'lr': 0.00014266640916739038, 'weight_decay': 1.4533182254699867e-06}. Best is trial 1 with value: 0.04896031740262075.\n",
      "[I 2025-04-06 14:39:09,603] Trial 5 finished with value: 0.060489209897606575 and parameters: {'embedding_dim': 128, 'dropout1': 0.2837028741157089, 'dropout2': 0.41549845865091106, 'lr': 0.005249586034568268, 'weight_decay': 0.0004013355159756002}. Best is trial 1 with value: 0.04896031740262075.\n",
      "[I 2025-04-06 14:43:14,139] Trial 6 finished with value: 0.054332259553345676 and parameters: {'embedding_dim': 128, 'dropout1': 0.0009001565904409037, 'dropout2': 0.340693167093742, 'lr': 0.001663666626196376, 'weight_decay': 0.00017387110786010824}. Best is trial 1 with value: 0.04896031740262075.\n",
      "[I 2025-04-06 14:45:42,995] Trial 7 finished with value: 0.05516204671443576 and parameters: {'embedding_dim': 32, 'dropout1': 0.3924768071745495, 'dropout2': 0.47702050839033905, 'lr': 0.007512081508286613, 'weight_decay': 5.1446051545433595e-06}. Best is trial 1 with value: 0.04896031740262075.\n",
      "[I 2025-04-06 14:49:42,466] Trial 8 finished with value: 0.05153217280834583 and parameters: {'embedding_dim': 128, 'dropout1': 0.3642259124991964, 'dropout2': 0.39790009490550177, 'lr': 0.0005215046364580312, 'weight_decay': 0.000122885375899389}. Best is trial 1 with value: 0.04896031740262075.\n",
      "[I 2025-04-06 14:53:43,351] Trial 9 finished with value: 0.04991630249786153 and parameters: {'embedding_dim': 128, 'dropout1': 0.1402968546784341, 'dropout2': 0.46805096449697464, 'lr': 0.0005259028280885295, 'weight_decay': 4.296492789041681e-06}. Best is trial 1 with value: 0.04896031740262075.\n",
      "[I 2025-04-06 14:56:34,005] Trial 10 finished with value: 0.05200675631994787 and parameters: {'embedding_dim': 64, 'dropout1': 0.47473599209447914, 'dropout2': 0.07127717522367087, 'lr': 0.00017845717558820584, 'weight_decay': 0.0022391753650561276}. Best is trial 1 with value: 0.04896031740262075.\n",
      "[I 2025-04-06 14:59:26,198] Trial 11 finished with value: 0.04803682636161544 and parameters: {'embedding_dim': 64, 'dropout1': 0.1466731395959771, 'dropout2': 0.10176679836851288, 'lr': 0.00037437427061499316, 'weight_decay': 7.492511338767275e-06}. Best is trial 11 with value: 0.04803682636161544.\n",
      "[I 2025-04-06 15:02:22,453] Trial 12 finished with value: 0.05008040717108221 and parameters: {'embedding_dim': 64, 'dropout1': 0.15577743522549448, 'dropout2': 0.08663643498685, 'lr': 0.001466156184062163, 'weight_decay': 1.482784267371322e-05}. Best is trial 11 with value: 0.04803682636161544.\n",
      "[I 2025-04-06 15:05:18,844] Trial 13 finished with value: 0.04900224164973084 and parameters: {'embedding_dim': 64, 'dropout1': 0.13659702039816113, 'dropout2': 0.14355472623033297, 'lr': 0.0002561860948549901, 'weight_decay': 1.2265059076496236e-06}. Best is trial 11 with value: 0.04803682636161544.\n",
      "[I 2025-04-06 15:08:17,061] Trial 14 finished with value: 0.048341957107503906 and parameters: {'embedding_dim': 64, 'dropout1': 0.2251052059557425, 'dropout2': 0.003768211076691619, 'lr': 0.00038123906612092207, 'weight_decay': 9.853149756500185e-06}. Best is trial 11 with value: 0.04803682636161544.\n",
      "[I 2025-04-06 15:11:18,876] Trial 15 finished with value: 0.04841051449505366 and parameters: {'embedding_dim': 64, 'dropout1': 0.2571188098927104, 'dropout2': 0.004195702225794897, 'lr': 0.0003015266896501836, 'weight_decay': 1.4682666045102956e-05}. Best is trial 11 with value: 0.04803682636161544.\n",
      "[I 2025-04-06 15:14:20,638] Trial 16 finished with value: 0.05163313593248577 and parameters: {'embedding_dim': 64, 'dropout1': 0.07763748849923582, 'dropout2': 0.012576168015007008, 'lr': 0.00010225747013756082, 'weight_decay': 1.0540863980051918e-05}. Best is trial 11 with value: 0.04803682636161544.\n",
      "[I 2025-04-06 15:17:25,513] Trial 17 finished with value: 0.0560754449198059 and parameters: {'embedding_dim': 64, 'dropout1': 0.2237094362328143, 'dropout2': 0.079410727017485, 'lr': 0.00034427222960396124, 'weight_decay': 0.009136757644748262}. Best is trial 11 with value: 0.04803682636161544.\n",
      "[I 2025-04-06 15:20:28,997] Trial 18 finished with value: 0.05252086607309 and parameters: {'embedding_dim': 64, 'dropout1': 0.2902271930986897, 'dropout2': 0.14625240595838976, 'lr': 0.001791640720697806, 'weight_decay': 4.888352804276316e-05}. Best is trial 11 with value: 0.04803682636161544.\n",
      "[I 2025-04-06 15:23:30,987] Trial 19 finished with value: 0.0482044388307457 and parameters: {'embedding_dim': 64, 'dropout1': 0.08105931863383606, 'dropout2': 0.29666564502815096, 'lr': 0.0004730222982166164, 'weight_decay': 7.126816521427609e-06}. Best is trial 11 with value: 0.04803682636161544.\n",
      "[W 2025-04-06 15:25:15,780] Trial 20 failed with parameters: {'embedding_dim': 32, 'dropout1': 0.07412510671171403, 'dropout2': 0.2936327902647131, 'lr': 0.0025965372750878443, 'weight_decay': 2.343780323970221e-06} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hjasi/Documentos/DeepLearning/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_64544/3222869113.py\", line 19, in objective\n",
      "    optimizer.step()\n",
      "  File \"/home/hjasi/Documentos/DeepLearning/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py\", line 493, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hjasi/Documentos/DeepLearning/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py\", line 91, in _use_grad\n",
      "    ret = func(self, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hjasi/Documentos/DeepLearning/.venv/lib/python3.12/site-packages/torch/optim/adam.py\", line 244, in step\n",
      "    adam(\n",
      "  File \"/home/hjasi/Documentos/DeepLearning/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py\", line 154, in maybe_fallback\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hjasi/Documentos/DeepLearning/.venv/lib/python3.12/site-packages/torch/optim/adam.py\", line 876, in adam\n",
      "    func(\n",
      "  File \"/home/hjasi/Documentos/DeepLearning/.venv/lib/python3.12/site-packages/torch/optim/adam.py\", line 460, in _single_tensor_adam\n",
      "    step = _get_value(step_t)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hjasi/Documentos/DeepLearning/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py\", line 106, in _get_value\n",
      "    return x.item() if isinstance(x, torch.Tensor) else x\n",
      "           ^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-04-06 15:25:15,781] Trial 20 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/DeepLearning/.venv/lib/python3.12/site-packages/optuna/study/study.py:475\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    375\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    385\u001b[39m \n\u001b[32m    386\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    473\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/DeepLearning/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/DeepLearning/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/DeepLearning/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:248\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    241\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    244\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    245\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    247\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/DeepLearning/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:197\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    199\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    200\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     17\u001b[39m         loss.backward()\n\u001b[32m     18\u001b[39m         torch.nn.utils.clip_grad_norm_(model.parameters(), \u001b[32m1.0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m         \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Validación final\u001b[39;00m\n\u001b[32m     22\u001b[39m model.eval()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/DeepLearning/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:493\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    488\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    489\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    490\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    491\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    496\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/DeepLearning/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:91\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     90\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     93\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/DeepLearning/.venv/lib/python3.12/site-packages/torch/optim/adam.py:244\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    232\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    234\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    235\u001b[39m         group,\n\u001b[32m    236\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    241\u001b[39m         state_steps,\n\u001b[32m    242\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/DeepLearning/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:154\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/DeepLearning/.venv/lib/python3.12/site-packages/torch/optim/adam.py:876\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    873\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    874\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m876\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/DeepLearning/.venv/lib/python3.12/site-packages/torch/optim/adam.py:460\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[39m\n\u001b[32m    458\u001b[39m     param.addcdiv_(exp_avg, denom)\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m     step = \u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    462\u001b[39m     bias_correction1 = \u001b[32m1\u001b[39m - beta1**step\n\u001b[32m    463\u001b[39m     bias_correction2 = \u001b[32m1\u001b[39m - beta2**step\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/DeepLearning/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:106\u001b[39m, in \u001b[36m_get_value\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, torch.Tensor) \u001b[38;5;28;01melse\u001b[39;00m x\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=30)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
